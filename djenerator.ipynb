{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "djent_generator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP5qN4c9UVEzoRmSh/9ZSFS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a7_d23wDkmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.autograd.variable import Variable\n",
        "import torchvision\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import sys\n",
        "import datetime\n",
        "import librosa\n",
        "import os\n",
        "from IPython.core.debugger import set_trace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qasa4mf4bSGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_rate = 44100\n",
        "seconds = 30\n",
        "\n",
        "placeholder_dataset = []\n",
        "\n",
        "for wav_file in os.listdir(\"./data\"):\n",
        "  if wav_file.endswith(\".wav\"):\n",
        "    y, sample_rate = librosa.load(path = os.path.join(\"./data/\", wav_file), sr = sample_rate, mono = True)\n",
        "    y = y[y != 0]\n",
        "    duration = y.shape[0] // sample_rate\n",
        "    for i in range(0, duration, seconds):\n",
        "      placeholder_dataset.append(y[i * sample_rate : (i + seconds) * sample_rate])\n",
        "\n",
        "num_subsamples = len(placeholder_dataset)\n",
        "\n",
        "dataset = np.empty((num_subsamples, sample_rate * seconds), np.float32)\n",
        "for data in placeholder_dataset:\n",
        "  np.append(dataset, data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbB0pJTudqYh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "c2a09302-0184-410b-f217-b70df92520a1"
      },
      "source": [
        "dataset = np.load(\"./data/dataset.npy\")\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save(\"./data/dataset.npy\", dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzEBIq3MaPj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, input_features, output_features):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.input_features = input_features\n",
        "    self.output_features = output_features\n",
        "\n",
        "    self.l_in = nn.Linear(self.input_features, 64, bias = False)\n",
        "    self.h1 = nn.Linear(64, 32, bias = False)\n",
        "    self.batch_norm = nn.BatchNorm1d(64, eps = 1e-03, momentum = 0.5)\n",
        "    self.l_out = nn.Linear(32, output_features, bias = False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.dropout(F.leaky_relu(self.l_in(x), 0.2, inplace=True), 0.2)\n",
        "    x = self.batch_norm(x)\n",
        "    x = F.dropout(F.leaky_relu(self.h1(x), 0.2, inplace=True), 0.2)\n",
        "    x = torch.sigmoid(self.l_out(x))\n",
        "    return x\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, input_features, output_features):\n",
        "    super(Generator, self).__init__()\n",
        "    self.input_features = input_features\n",
        "    self.output_features = output_features\n",
        "\n",
        "    self.l_in = nn.Linear(self.input_features, 32)\n",
        "    self.batch_norm1 = nn.BatchNorm1d(32, eps = 1e-04, momentum = 0.4)\n",
        "    self.h1 = nn.Linear(32, 64)\n",
        "    self.batch_norm2 = nn.BatchNorm1d(64, eps = 1e-04, momentum = 0.2)\n",
        "    self.h2 = nn.Linear(64, 128)\n",
        "    self.l_out = nn.Linear(128, output_features)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.l_in(x), inplace = True)\n",
        "    x = self.batch_norm1(x)\n",
        "    x = F.dropout(F.relu(self.h1(x), inplace = True), 0.2)\n",
        "    x = self.batch_norm2(x)\n",
        "    x = F.dropout(F.relu(self.h2(x), inplace = True), 0.2)\n",
        "    x = torch.tanh(self.l_out(x))\n",
        "    return x\n",
        "\n",
        "class GAN():\n",
        "  def __init__(self, dataset, batch_size, shuffle, song_features, noise_vector_latent_dim, num_output_samples):\n",
        "    \n",
        "    self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    self.dataset = dataset\n",
        "    self.batch_size = batch_size\n",
        "    self.shuffle = shuffle\n",
        "    self.song_features = song_features\n",
        "\n",
        "    self.data_loader = torch.utils.data.DataLoader(self.dataset, batch_size = self.batch_size, shuffle = self.shuffle)\n",
        "    self.num_batches = len(self.data_loader)\n",
        "    \n",
        "    self.noise_vector_latent_dim = noise_vector_latent_dim\n",
        "    self.num_output_samples = num_output_samples\n",
        "\n",
        "    self.discriminator = Discriminator(input_features = song_features, output_features = 1)\n",
        "    self.generator = Generator(input_features = noise_vector_latent_dim, output_features = song_features)\n",
        "    self.discriminator = self.discriminator.to(self.device)\n",
        "    self.generator = self.generator.to(self.device)\n",
        "\n",
        "    self.d_opt = optim.RMSprop(self.discriminator.parameters(), lr = 0.001, alpha = 0.7, eps = 1e-05, weight_decay = 1e-03)\n",
        "    self.g_opt = optim.RMSprop(self.generator.parameters(), lr = 0.001, alpha = 0.7, eps = 1e-05, weight_decay = 1e-03)\n",
        "    \n",
        "    self.samples = []\n",
        "\n",
        "    self.BCELoss = nn.BCELoss()\n",
        "    self.BCELoss = self.BCELoss.to(self.device)\n",
        "\n",
        "  def train_disc(self, opt, real, fake, step):\n",
        "    opt.zero_grad()\n",
        "    \n",
        "    smoothed_labels = np.zeros((real.size(0), 1), dtype = np.float32)\n",
        "    for i in range(len(smoothed_labels)):\n",
        "      smoothed_labels[i] = 0.9\n",
        "    smoothed_labels = torch.from_numpy(smoothed_labels)\n",
        "    smoothed_labels = smoothed_labels.to(self.device)\n",
        "\n",
        "    pred_real = self.discriminator(real)\n",
        "    error_real = self.BCELoss(pred_real, smoothed_labels)\n",
        "    error_real.backward()\n",
        "\n",
        "    pred_fake = self.discriminator(fake)\n",
        "    error_fake = self.BCELoss(pred_fake, torch.zeros(real.size(0), 1).to(self.device))\n",
        "    error_fake.backward()\n",
        "\n",
        "    opt.step()\n",
        "\n",
        "    return error_real, error_fake, error_real + error_fake\n",
        "\n",
        "  def train_gen(self, opt, fake, step):\n",
        "    opt.zero_grad()\n",
        "    \n",
        "    smoothed_labels = np.zeros((fake.size(0), 1), dtype = np.float32)\n",
        "    for i in range(len(smoothed_labels)):\n",
        "      smoothed_labels[i] = 0.9\n",
        "    smoothed_labels = torch.from_numpy(smoothed_labels)\n",
        "    smoothed_labels = smoothed_labels.to(self.device)\n",
        "    \n",
        "    pred_fake = self.discriminator(fake)\n",
        "    error_fake = self.BCELoss(pred_fake, smoothed_labels)\n",
        "    error_fake.backward()\n",
        "\n",
        "    opt.step()\n",
        "\n",
        "    return error_fake\n",
        "\n",
        "  def noise(self,  N):\n",
        "    x = torch.randn((N, self.noise_vector_latent_dim))\n",
        "    return x.to(self.device)\n",
        "    \n",
        "  def challenge_discriminator(self, real: torch.Tensor, noise_size: int, rate: float):\n",
        "    chance = np.random.randint(0, 100)\n",
        "    real = real.to(self.device)\n",
        "    x = torch.randn(noise_size)\n",
        "    if chance <= int(rate * 100):\n",
        "      return real + 0.2 * x.to(self.device)\n",
        "    else:\n",
        "      return real\n",
        "\n",
        "  def vec2wave(self, vec, size):\n",
        "    return vec.view(vec.size(0), size)\n",
        "\n",
        "  def train(self, epochs, start_epoch, eval_every, save_every):\n",
        "    step = 0\n",
        "\n",
        "    test_noise = self.noise(self.num_output_samples)\n",
        "    test_noise.to(self.device)\n",
        "    \n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    sys.stdout.write(\"\\r\" + \"Going into train mode\")\n",
        "    self.discriminator.train()\n",
        "    self.generator.train()\n",
        "    \n",
        "    for epoch in range(start_epoch, epochs):\n",
        "      for n_batch, real in enumerate(self.data_loader):\n",
        "        N = real.size(0)\n",
        "        step += 1\n",
        "\n",
        "        real = real.view(N, self.song_features)\n",
        "\n",
        "        noisify_real_rate = 0.01\n",
        "        if step % 50 == 0:\n",
        "          noisify_real_rate = 0.3\n",
        "        if step % 100 == 0:\n",
        "          noisify_real_rate = 0.5\n",
        "        if step % 1000 == 0:\n",
        "          noisify_real_rate = 0.7\n",
        "\n",
        "        real = self.challenge_discriminator(real = real, noise_size = self.song_features, rate = noisify_real_rate)\n",
        "        real = real.to(self.device)\n",
        "        \n",
        "        fake = self.generator(self.noise(N)).detach()\n",
        "        fake = fake.to(self.device)\n",
        "        \n",
        "        d_error_real, d_error_fake, d_error_total = self.train_disc(self.d_opt, real, fake, step)\n",
        "\n",
        "        fake = self.generator(self.noise(N))\n",
        "        fake = fake.to(self.device)\n",
        "        \n",
        "        g_error = self.train_gen(self.g_opt, fake, step)\n",
        "        \n",
        "        sys.stdout.write(\"\\r\" + f\"d_error_real = {d_error_real:.2f} -> d_error_fake = {d_error_fake:.2f} -> d_error_total = {d_error_total:.2f} -> g_error = {g_error:.2f} -> epoch = {epoch + 1} -> batch = {n_batch + 1} / {self.num_batches}\")\n",
        "\n",
        "        if (epoch + 1) % eval_every == 0 and n_batch == 0:\n",
        "          sys.stdout.write(\"\\r\" + \"Updating list of samples\")\n",
        "          self.samples.append(self.vec2wave(self.generator(test_noise), self.song_features).cpu().data)\n",
        "          np.save(f\"./djenerated_samples_raw/{self.num_output_samples}_samples_at_epoch_{epoch + 1}.npy\", self.samples[-1].numpy())\n",
        "        \n",
        "        if (epoch + 1) % save_every == 0 and n_batch == 0:\n",
        "            sys.stdout.write(\"\\r\" + \"Saving Discriminator model | Saving Generator model\")\n",
        "            torch.save(\n",
        "              {\n",
        "                  \"epoch\" : epoch,\n",
        "                  \"model_state_dict\" : self.discriminator.state_dict(),\n",
        "                  \"optimizer_state_dict\" : self.d_opt.state_dict()\n",
        "              }, \n",
        "              \"./models/discriminator.pth\")\n",
        "\n",
        "            torch.save(\n",
        "            {\n",
        "              \"epoch\" : epoch,\n",
        "              \"model_state_dict\" : self.generator.state_dict(),\n",
        "              \"optimizer_state_dict\" : self.g_opt.state_dict()\n",
        "            }, \n",
        "            \"./models/generator.pth\")    \n",
        "\n",
        "        \n",
        "  def resume_training(self, epochs, eval_every, save_every):\n",
        "    sys.stdout.write(\"\\r\" + \"Loading checkpoints\")\n",
        "    discriminator_checkpoint = torch.load(\"./models/discriminator.pth\")\n",
        "    generator_checkpoint = torch.load(\"./models/generator.pth\")\n",
        "\n",
        "    sys.stdout.write(\"\\r\" + \"Getting most recent epoch\")\n",
        "    start_epoch = discriminator_checkpoint['epoch']\n",
        "    \n",
        "    sys.stdout.write(\"\\r\" + \"Loading optimizers\")\n",
        "    self.d_opt.load_state_dict(discriminator_checkpoint['optimizer_state_dict'])\n",
        "    self.g_opt.load_state_dict(generator_checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    sys.stdout.write(\"\\r\" + \"Loading models\")\n",
        "    self.discriminator.load_state_dict(discriminator_checkpoint['model_state_dict'])\n",
        "    self.generator.load_state_dict(generator_checkpoint['model_state_dict'])\n",
        "\n",
        "    self.discriminator = self.discriminator.to(self.device)\n",
        "    self.generator = self.generator.to(self.device)\n",
        "    \n",
        "    sys.stdout.write(\"\\r\" + \"Fetching batch norm gradients\")\n",
        "    self.discriminator.eval()\n",
        "    self.generator.eval()\n",
        "    \n",
        "    self.train(epochs = epochs, start_epoch = start_epoch, eval_every = eval_every, save_every = save_every)\n",
        "\n",
        "  def load_generator(self):\n",
        "    generator_checkpoint = torch.load(\"./models/generator.pth\")\n",
        "    self.generator.load_state_dict(generator_checkpoint['model_state_dict'])\n",
        "    return self.generator\n",
        "\n",
        "  def get_all_generated_samples(self):\n",
        "    return self.samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxWYhR4aj5A_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan = GAN(\n",
        "  dataset = dataset,\n",
        "  batch_size = 9,\n",
        "  shuffle = True,\n",
        "  song_features = sample_rate * seconds, \n",
        "  noise_vector_latent_dim = 100,\n",
        "  num_output_samples = 9\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRvuTsoiT6-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan.train(start_epoch = 0, epochs = 100000, eval_every = 1000, save_every = 2500)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}