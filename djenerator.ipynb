{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "djent_generator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ZbOnT7fn6EyVfkWsnQuQQ8MYtK6ybrBx",
      "authorship_tag": "ABX9TyNrf7Ds0a6hlW+Zl1IxH5cf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLw283NNzTWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv ./models ./drive/My\\ Drive/Djenerator"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a7_d23wDkmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.autograd.variable import Variable\n",
        "import torchvision\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import sys\n",
        "import datetime\n",
        "import librosa\n",
        "import os\n",
        "from IPython.core.debugger import set_trace"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qasa4mf4bSGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_rate = 44100\n",
        "seconds = 30\n",
        "\n",
        "placeholder_dataset = []\n",
        "\n",
<<<<<<< HEAD
        "for wav_file in os.listdir(\"./data\"):\n",
        "  if wav_file.endswith(\".wav\"):\n",
        "    y, sample_rate = librosa.load(path = os.path.join(\"./data/\", wav_file), sr = sample_rate, mono = True)\n",
=======
        "for wav_file in os.listdir(\"/content/drive/My Drive/Djenerator/data\"):\n",
        "  if wav_file.endswith(\".wav\"):\n",
        "    y, sample_rate = librosa.load(path = f\"/content/drive/My Drive/Djenerator/data/{wav_file}\", sr = sample_rate)\n",
>>>>>>> 62315f2508d559fbb5cf5a96f44e7fe5b228d3f8
        "    y = y[y != 0]\n",
        "    duration = y.shape[0] // sample_rate\n",
        "    for i in range(0, duration, seconds):\n",
        "      placeholder_dataset.append(y[i * sample_rate : (i + seconds) * sample_rate])\n",
        "\n",
        "num_subsamples = len(placeholder_dataset)\n",
        "\n",
<<<<<<< HEAD
        "dataset = np.empty((num_subsamples, sample_rate * seconds), np.float32)\n",
        "for data in placeholder_dataset:\n",
        "  np.append(dataset, data)"
=======
        "dataset = np.empty((num_subsamples, sample_rate * seconds), dtype = np.float32)\n",
        "\n",
        "for wav_file in os.listdir(\"/content/drive/My Drive/Djenerator/data/\"):\n",
        "  if wav_file.endswith(\".wav\"):\n",
        "    y, sample_rate = librosa.load(path = f\"/content/drive/My Drive/Djenerator/data/{wav_file}\", sr = sample_rate)\n",
        "    y = y[y != 0]\n",
        "    duration = y.shape[0] // sample_rate\n",
        "    for i in range(0, duration, seconds):\n",
        "      np.append(dataset, y[i * sample_rate : (i + seconds) * sample_rate])\n",
        "      # dataset.append(y[i * sample_rate : (i + 1) * sample_rate])"
>>>>>>> 62315f2508d559fbb5cf5a96f44e7fe5b228d3f8
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbB0pJTudqYh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "a64f92b9-8851-4c35-c310-e3db06e4569f"
      },
      "source": [
<<<<<<< HEAD
        "dataset = np.load(\"./data/dataset.npy\")\n",
        "dataset"
=======
        "dataset.shape, np.max(dataset[2]), np.min(dataset[2]), dataset"
>>>>>>> 62315f2508d559fbb5cf5a96f44e7fe5b228d3f8
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50, 1323000),\n",
              " 0.5631256,\n",
              " -0.5678406,\n",
              " array([[ 1.5258789e-05, -1.5258789e-05,  3.0517578e-05, ...,\n",
              "         -2.2033691e-02, -2.1316528e-02, -4.6112061e-02],\n",
              "        [-5.3390503e-02, -5.1086426e-02, -2.0339966e-02, ...,\n",
              "          7.4005127e-03,  1.6098022e-02,  2.4765015e-02],\n",
              "        [ 3.1936646e-02,  3.7017822e-02,  4.0191650e-02, ...,\n",
              "         -4.8599243e-02, -3.6102295e-02, -3.3523560e-02],\n",
              "        ...,\n",
              "        [ 2.3559570e-01,  3.6682129e-02,  2.0269775e-01, ...,\n",
              "          8.3251953e-02,  1.7260742e-01,  5.6945801e-02],\n",
              "        [ 1.8127441e-01,  2.0202637e-02,  1.6107178e-01, ...,\n",
              "          8.7982178e-02, -7.5408936e-02,  9.0087891e-02],\n",
              "        [-8.8562012e-02,  8.0749512e-02, -7.7148438e-02, ...,\n",
              "         -1.7547607e-01, -5.8441162e-02, -2.9122925e-01]], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save(\"./data/dataset.npy\", dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzEBIq3MaPj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, input_features, output_features):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.input_features = input_features\n",
        "    self.output_features = output_features\n",
        "\n",
        "    self.l_in = nn.Sequential(\n",
        "        nn.Linear(\n",
        "            in_features = self.input_features,\n",
        "            out_features = 64\n",
        "        ),\n",
        "        nn.LeakyReLU(\n",
        "            negative_slope = 0.2\n",
        "        ),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "    self.batch_norm = nn.BatchNorm1d(64, eps = 1e-03, momentum = 0.5)\n",
        "\n",
        "\n",
        "    self.h1 = nn.Sequential(\n",
        "        nn.Linear(\n",
        "            in_features = 64,\n",
        "            out_features = 32\n",
        "        ),\n",
        "        nn.LeakyReLU(\n",
        "            negative_slope = 0.2\n",
        "        ),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "\n",
        "    self.l_out = nn.Sequential(\n",
        "        nn.Linear(\n",
        "            in_features = 32,\n",
        "            out_features = output_features\n",
        "        ),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "    \n",
        "    self.l_in = self.l_in.cuda()\n",
        "    self.batch_norm = self.batch_norm.cuda()\n",
        "    self.h1 = self.h1.cuda()\n",
        "    self.l_out = self.l_out.cuda()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.l_in(x)\n",
        "    x = self.batch_norm(x)\n",
        "    x = self.h1(x)\n",
        "    x = self.l_out(x)\n",
        "    return x\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, input_features, output_features):\n",
        "    super(Generator, self).__init__()\n",
        "    self.input_features = input_features\n",
        "    self.output_features = output_features\n",
        "\n",
        "    self.l_in = nn.Sequential(\n",
        "        nn.Linear(\n",
        "            in_features = self.input_features,\n",
        "            out_features = 32\n",
        "        ),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.batch_norm1 = nn.BatchNorm1d(32, eps = 1e-04, momentum = 0.4)\n",
        "\n",
        "    self.h1 = nn.Sequential(\n",
        "        nn.Linear(\n",
        "            in_features = 32,\n",
        "            out_features = 64\n",
        "        ),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.batch_norm2 = nn.BatchNorm1d(64, eps = 1e-04, momentum = 0.2)\n",
        "\n",
        "    self.h2 = nn.Sequential(\n",
        "        nn.Linear(\n",
        "            in_features = 64,\n",
        "            out_features = 128\n",
        "        ),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.l_out = nn.Sequential(\n",
        "        nn.Linear(\n",
        "            in_features = 128,\n",
        "            out_features = output_features\n",
        "        ),\n",
        "        nn.Tanh()\n",
        "    )\n",
<<<<<<< HEAD
        "    \n",
        "    self.l_in = self.l_in.cuda()\n",
        "    self.batch_norm1 = self.batch_norm1.cuda()\n",
        "    self.h1 = self.h1.cuda()\n",
        "    self.batch_norm2 = self.batch_norm2.cuda()\n",
        "    self.h2 = self.h2.cuda()\n",
        "    self.l_out = self.l_out.cuda()\n",
=======
        "\n",
        "  def nn_sin(self, x):\n",
        "    return x * torch.sin(x)\n",
>>>>>>> 62315f2508d559fbb5cf5a96f44e7fe5b228d3f8
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.l_in(x)\n",
        "    x = self.batch_norm1(x)\n",
        "    x = self.h1(x)\n",
        "    x = self.batch_norm2(x)\n",
        "    x = self.h2(x)\n",
<<<<<<< HEAD
        "    x = self.l_out(x)\n",
=======
        "    x = self.nn_sin(self.l_out(x))\n",
>>>>>>> 62315f2508d559fbb5cf5a96f44e7fe5b228d3f8
        "    return x\n",
        "\n",
        "class GAN():\n",
        "  def __init__(self, dataset, batch_size, shuffle, song_features, noise_vector_latent_dim, num_output_samples):\n",
        "    \n",
        "    self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    self.dataset = dataset\n",
        "    self.batch_size = batch_size\n",
        "    self.shuffle = shuffle\n",
        "\n",
        "    self.song_features = song_features\n",
        "\n",
        "    self.noise_vector_latent_dim = noise_vector_latent_dim\n",
        "    self.num_output_samples = num_output_samples\n",
        "\n",
        "    self.data_loader = torch.utils.data.DataLoader(self.dataset, batch_size = self.batch_size, shuffle = self.shuffle)\n",
        "    self.num_batches = len(self.data_loader)\n",
        "\n",
        "    self.discriminator = Discriminator(input_features = song_features, output_features = 1)\n",
        "    self.generator = Generator(input_features = noise_vector_latent_dim, output_features = song_features)\n",
        "    \n",
        "    self.discriminator = self.discriminator.to(self.device)\n",
        "    self.generator = self.generator.to(self.device)\n",
        "\n",
        "#     self.d_opt = optim.Adam(self.discriminator.parameters(), lr = 0.0001, betas=(0.5, 0.999))\n",
        "#     self.g_opt = optim.Adam(self.generator.parameters(), lr = 0.0001, betas=(0.5, 0.999))\n",
        "\n",
        "    self.d_opt = optim.RMSprop(self.discriminator.parameters(), lr = 0.001, alpha = 0.7, eps = 1e-05)\n",
        "    self.g_opt = optim.RMSprop(self.generator.parameters(), lr = 0.001, alpha = 0.7, eps = 1e-05)\n",
        "    \n",
        "    self.samples = []\n",
        "\n",
        "    self.BCELoss = nn.BCELoss()\n",
        "    self.BCELoss = self.BCELoss.to(self.device)\n",
        "\n",
        "  def train_disc(self, opt, real, fake, step):\n",
        "    opt.zero_grad()\n",
        "\n",
        "    self.pred_real = self.discriminator(real)\n",
        "\n",
        "    smoothed_labels = np.zeros((real.size(0), 1), dtype = np.float32)\n",
        "    for i in range(len(smoothed_labels)):\n",
        "      smoothed_labels[i] = 0.9\n",
        "    smoothed_labels = torch.from_numpy(smoothed_labels)\n",
        "    smoothed_labels = smoothed_labels.to(self.device)\n",
        "    \n",
        "    self.error_real = self.BCELoss(self.pred_real, smoothed_labels)\n",
        "    self.error_real.backward()\n",
        "\n",
        "    self.pred_fake = self.discriminator(fake)\n",
        "    self.error_fake = self.BCELoss(self.pred_fake, torch.zeros(real.size(0), 1).to(self.device))\n",
        "    self.error_fake.backward()\n",
        "\n",
        "    opt.step()\n",
        "\n",
        "    return self.error_real, self.error_fake, self.error_real + self.error_fake\n",
        "\n",
        "  def train_gen(self, opt, fake, step):\n",
        "    opt.zero_grad()\n",
        "    \n",
        "    smoothed_labels = np.zeros((fake.size(0), 1), dtype = np.float32)\n",
        "    for i in range(len(smoothed_labels)):\n",
        "      smoothed_labels[i] = 0.9\n",
        "    smoothed_labels = torch.from_numpy(smoothed_labels)\n",
        "    smoothed_labels = smoothed_labels.to(self.device)\n",
        "    \n",
        "    self.pred_fake = self.discriminator(fake)\n",
        "    self.error_fake = self.BCELoss(self.pred_fake, smoothed_labels)\n",
        "    self.error_fake.backward()\n",
        "\n",
        "    opt.step()\n",
        "\n",
        "    return self.error_fake\n",
        "\n",
        "  def noise(self,  N):\n",
        "    x = torch.randn((N, self.noise_vector_latent_dim))\n",
        "    return x.to(self.device)\n",
        "    \n",
        "  def challenge_discriminator(self, real: torch.Tensor, noise_size: int, rate: float):\n",
        "    chance = np.random.randint(0, 100)\n",
        "    real = real.to(self.device)\n",
        "    x = torch.randn(noise_size)\n",
        "    if chance <= int(rate * 100):\n",
        "      return real + 0.2 * x.to(self.device)\n",
        "    else:\n",
        "      return real\n",
        "\n",
        "  def vec2wave(self, vec, size):\n",
        "    return vec.view(vec.size(0), size)\n",
        "\n",
        "  def train(self, epochs, start_epoch, eval_every):\n",
        "    step = 0\n",
        "\n",
        "    test_noise = self.noise(self.num_output_samples)\n",
        "    test_noise.to(self.device)\n",
        "    \n",
        "    torch.backends.cudnn.benchmark=True\n",
        "    \n",
        "    for epoch in range(start_epoch, epochs):\n",
        "      for n_batch, real in enumerate(self.data_loader):\n",
        "        N = real.size(0)\n",
        "        step += 1\n",
        "\n",
        "        real = real.view(N, self.song_features)\n",
        "\n",
        "        noisify_real_rate = 0.01\n",
        "        if step % 50 == 0:\n",
        "          noisify_real_rate = 0.3\n",
        "        if step % 100 == 0:\n",
        "          noisify_real_rate = 0.5\n",
        "        if step % 1000 == 0:\n",
        "          noisify_real_rate = 0.7\n",
        "\n",
        "        real = self.challenge_discriminator(real = real, noise_size = self.song_features, rate = noisify_real_rate)\n",
        "        real = real.to(self.device)\n",
        "        \n",
        "        fake = self.generator(self.noise(N)).detach()\n",
        "        fake = fake.to(self.device)\n",
        "        \n",
        "        d_error_real, d_error_fake, d_error_total = self.train_disc(self.d_opt, real, fake, step)\n",
        "\n",
        "        fake = self.generator(self.noise(N))\n",
        "        fake = fake.to(self.device)\n",
        "        \n",
        "        g_error = self.train_gen(self.g_opt, fake, step)\n",
        "        \n",
        "        sys.stdout.write(\"\\r\" + f\"d_error_real = {d_error_real:.2f} -> d_error_fake = {d_error_fake:.2f} -> d_error_total = {d_error_total:.2f} -> g_error = {g_error:.2f} -> epoch = {epoch + 1} -> batch = {n_batch + 1} / {self.num_batches}\")\n",
        "\n",
        "        if (epoch + 1) % eval_every == 0 and n_batch == 0:\n",
        "          sys.stdout.write(\"\\r\" + \"Updating list of samples | Saving Discriminator model | Saving Generator model\")\n",
        "\n",
        "          torch.save(\n",
        "          {\n",
        "              \"epoch\" : epoch,\n",
        "              \"model_state_dict\" : self.discriminator.state_dict(),\n",
        "              \"optimizer_state_dict\" : self.d_opt.state_dict(),\n",
        "              \"losses\" : [d_error_real, d_error_fake, d_error_total]\n",
        "          }, \n",
        "          \"/content/drive/My Drive/Djenerator/models/discriminator.pth\")\n",
        "\n",
        "          torch.save(\n",
        "          {\n",
        "              \"epoch\" : epoch,\n",
        "              \"model_state_dict\" : self.generator.state_dict(),\n",
        "              \"optimizer_state_dict\" : self.g_opt.state_dict(),\n",
        "              \"losses\" : [g_error]\n",
        "          }, \n",
<<<<<<< HEAD
        "          \"./models/generator.pth\")    \n",
        "\n",
        "          self.samples.append(self.vec2wave(self.generator(test_noise), self.song_features).cpu().data)\n",
        "          np.save(f\"./djenerated_samples_raw/{self.num_output_samples}_samples_at_epoch_{epoch + 1}.npy\", self.samples[-1].numpy())  \n",
        "        \n",
        "  def resume_training(self, epochs, eval_every):\n",
        "    sys.stdout.write(\"\\r\" + \"Loading discriminator and generator models\")\n",
        "    discriminator_checkpoint = torch.load(\"./models/discriminator.pth\")\n",
        "    generator_checkpoint = torch.load(\"./models/generator.pth\")\n",
=======
        "          \"/content/drive/My Drive/Djenerator/models/generator.pth\")    \n",
        "\n",
        "          self.samples.append(self.vec2wave(self.generator(test_noise), self.song_features).data)\n",
        "          np.save(f\"./content/drive/My Drive/Djenerator/djenerated_samples_raw/{self.num_output_samples}_samples_at_epoch_{epoch + 1}.npy\", self.samples[-1].numpy())  \n",
        "        \n",
        "  def resume_gan_training(self, epochs, eval_every):\n",
        "    sys.stdout.write(\"\\r\" + \"Loading discriminator and generator models\")\n",
        "    discriminator_checkpoint = torch.load(\"/content/drive/My Drive/Djenerator/models/discriminator.pth\")\n",
        "    generator_checkpoint = torch.load(\"/content/drive/My Drive/Djenerator/models/generator.pth\")\n",
>>>>>>> 62315f2508d559fbb5cf5a96f44e7fe5b228d3f8
        "\n",
        "    sys.stdout.write(\"\\r\" + \"Getting most recent epoch\")\n",
        "    start_epoch = discriminator_checkpoint['epoch']\n",
        "    \n",
        "    sys.stdout.write(\"\\r\" + \"Loading discriminator optimizers\")\n",
<<<<<<< HEAD
        "    self.d_opt.load_state_dict(discriminator_checkpoint['optimizer_state_dict'])\n",
        "    self.discriminator.load_state_dict(discriminator_checkpoint['model_state_dict'])\n",
        "    \n",
=======
        "    self.d_opt = discriminator_checkpoint['optimizer_state_dict']\n",
        "    self.discriminator.load_state_dict(discriminator_checkpoint['model_state_dict'])\n",
        "\n",
>>>>>>> 62315f2508d559fbb5cf5a96f44e7fe5b228d3f8
        "    sys.stdout.write(\"\\r\" + \"Loading discriminator losses\")\n",
        "    d_error_real, d_error_fake, d_error_total = discriminator_checkpoint['losses'][0], discriminator_checkpoint['losses'][1], discriminator_checkpoint['losses'][2]\n",
        "\n",
        "    sys.stdout.write(\"\\r\" + \"Loading generator optimizers\")\n",
<<<<<<< HEAD
        "    self.g_opt.load_state_dict(generator_checkpoint['optimizer_state_dict'])\n",
=======
        "    self.g_opt = generator_checkpoint['optimizer_state_dict']\n",
>>>>>>> 62315f2508d559fbb5cf5a96f44e7fe5b228d3f8
        "    self.generator.load_state_dict(generator_checkpoint['model_state_dict'])\n",
        "\n",
        "    sys.stdout.write(\"\\r\" + \"Loading generator loss\")\n",
        "    g_error = generator_checkpoint['losses'][0]\n",
        "\n",
<<<<<<< HEAD
        "    self.discriminator = self.discriminator.to(self.device)\n",
        "    self.generator = self.generator.to(self.device)\n",
        "    \n",
=======
>>>>>>> 62315f2508d559fbb5cf5a96f44e7fe5b228d3f8
        "    sys.stdout.write(\"\\r\" + \"Fetching batch norm gradients\")\n",
        "    self.discriminator.eval()\n",
        "    self.generator.eval()\n",
        "\n",
        "    sys.stdout.write(\"\\r\" + \"Setting models in train mode\")\n",
        "    self.discriminator.train()\n",
        "    self.generator.train()\n",
        "\n",
<<<<<<< HEAD
        "    \n",
        "    self.train(epochs = epochs, start_epoch = start_epoch, eval_every = eval_every)\n",
        "\n",
        "  def load_generator(self):\n",
        "    generator_checkpoint = torch.load(\"./models/generator.pth\")\n",
        "    self.generator.load_state_dict(generator_checkpoint['model_state_dict'])\n",
        "    return self.generator\n",
        "\n",
=======
        "    self.train(epochs = epochs, start_epoch = epoch, eval_every = eval_every)\n",
        "  \n",
>>>>>>> 62315f2508d559fbb5cf5a96f44e7fe5b228d3f8
        "  def get_all_generated_samples(self):\n",
        "    return self.samples"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxWYhR4aj5A_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan = GAN(\n",
        "  dataset = dataset,\n",
<<<<<<< HEAD
        "  batch_size = 16,\n",
=======
        "  batch_size = 10,\n",
>>>>>>> 62315f2508d559fbb5cf5a96f44e7fe5b228d3f8
        "  shuffle = True,\n",
        "  song_features = sample_rate * seconds, \n",
        "  noise_vector_latent_dim = 100,\n",
        "  num_output_samples = 20\n",
        ")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRvuTsoiT6-g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "21c63ebb-8a5b-4c85-a4ce-5ea046e8aa9d"
      },
      "source": [
        "gan.train(start_epoch = 0, epochs = 100000, eval_every = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "d_error_real = 0.70 -> d_error_fake = 0.29 -> d_error_total = 0.99 -> g_error = 2.01 -> epoch = 244 -> batch = 3 / 5"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byYEmG_J1iuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan.resume_gan_training(epochs = 100000, eval_every = 300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbxhEyL7IrSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "gan.train(start_epoch = 0, epochs = 100000, eval_every = 500)"
=======
        "samples = gan.get_all_generated_samples()"
>>>>>>> 62315f2508d559fbb5cf5a96f44e7fe5b228d3f8
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}